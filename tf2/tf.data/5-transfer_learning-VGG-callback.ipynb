{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 180, 180) # Add 6 pixels of padding\n",
    "    image = tf.image.random_crop(image, size=[150, 150, 3]) # Random crop back to 28x28\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"D:/dataset/flower_photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*') if item.name != \"LICENSE.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = tf.data.Dataset.list_files(str(train_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  3670\n",
      "train size:  2936\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = len(list(full_dataset))\n",
    "print(\"Dataset size: \", DATASET_SIZE)\n",
    "train_size = int((1-validation_split) * DATASET_SIZE)\n",
    "print(\"train size: \", train_size)\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "validation_dataset = full_dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label(\"D:\\\\dataset\\\\flower_photos\\\\daisy\\\\5547758_eea9edfd54_n.jpg\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/44942729/tensorflowvalueerror-images-contains-no-shape\n",
    "    img = tf.image.decode_image(img, 3, expand_animations=False)\n",
    "    \n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = (image / 127.5) - 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image,height, width):\n",
    "    image = tf.image.resize(image, (height, width),\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    #image = tf.image.resize_with_crop_or_pad(image, height, width)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_with_label(image_path):\n",
    "    label = get_label(image_path)\n",
    "    img = load_img(image_path)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "    image, label = load_image_with_label(image_file)\n",
    "    image = augment_data(image)\n",
    "    image = normalize(image)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(image_file):\n",
    "    image, label = load_image_with_label(image_file)\n",
    "    image = resize(image, 150, 150)\n",
    "    image = normalize(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(load_image_train)\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = validation_dataset.map(load_image_test)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class =len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dense_layer = tf.keras.layers.Dense(100, activation='relu')\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "prediction_layer = tf.keras.layers.Dense(n_class, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  flatten_layer,\n",
    "  dense_layer,\n",
    "  dropout_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from train_utils import get_scheduler\n",
    "from datetime import datetime\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_scheduler(model, \"lr.txt\")\n",
    "lr_decay = LearningRateScheduler(scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "model_dir = os.path.join(os.path.expanduser(\"/mnt/datasets/checkpoints/logo/\"), subdir)\n",
    "if not os.path.isdir(model_dir):  # Create the model directory if it doesn't exist\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "    \n",
    "filepath = os.path.join(model_dir, \"weights-{epoch:02d}.hdf5\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.path.expanduser(\"./logs/vggg16\"), subdir)\n",
    "if not os.path.isdir(log_dir):  # Create the log directory if it doesn't exist\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "tensorboard=TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=100,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[lr_decay, checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-GPU",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
